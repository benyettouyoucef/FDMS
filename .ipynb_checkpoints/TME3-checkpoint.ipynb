{
 "metadata": {
  "name": "",
  "signature": "sha256:3a9a706ae622779ea569431cb5eca33b18a06b777e7f2ae0bde039dcb33d11d8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline \n",
      "import numpy as np\n",
      "from sklearn import datasets\n",
      "from sklearn import metrics\n",
      "from sklearn import tree\n",
      "from sklearn import cross_validation\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "\n",
      "class bagging():\n",
      "\n",
      "    def __init__(self,B=5):\n",
      "        self.B = B #nombre de classifieurs\n",
      "        \n",
      "        \n",
      "   \n",
      "    def fit(self, X,Y):\n",
      "        n = X.shape[0] #nombre d'exemple\n",
      "        n_class = n/self.B #sous ensemble pour mes classifieurs\n",
      "        self.clf = [tree.DecisionTreeClassifier(max_depth=1) for i in range(self.B)] #initialisation des classifeur (stump) \n",
      "        for i in xrange(self.B): #train\n",
      "            ids = np.random.choice(n,n_class) #on tire des point depuis {} d'exemple pour apprendre\n",
      "            self.clf[i]= self.clf[i].fit(X[ids],Y[ids]) #on entraine chaque classifieur sur cet ensemble\n",
      "        \n",
      "    def prediction(self, X):\n",
      "        out = []\n",
      "        for i in xrange(len(X)): #pour chaque exemple on va le test\u00e9 sur nos classiffieurs d\u00e9ja apris\n",
      "            result = []\n",
      "            for j in xrange(self.B): #prediction\n",
      "                result.append(self.clf[j].predict(X[i].reshape(1, X.shape[1]))) \n",
      "            out.append(np.sign(np.sum(result))) #on prend le vote majoritaire des clf\n",
      "        return np.array(out)\n",
      "\n",
      "    def accuracy(self, pred , Y):\n",
      "        acc = pred - Y\n",
      "        return 100.0*len(np.where(acc == 0)[0])/len(pred)*1.0  \n",
      "\n",
      "\n",
      "\n",
      "breast_cancer_scale = datasets.fetch_mldata('breast-cancer_scale')\n",
      "X=breast_cancer_scale.data\n",
      "Y=breast_cancer_scale.target\n",
      "\n",
      "Y[np.where(Y == 4)] = 1\n",
      "Y[np.where(Y == 2)] = -1\n",
      "\n",
      "\n",
      "xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(X, Y, test_size=0.2, random_state=0)\n",
      "\n",
      "bag = bagging(B=2)\n",
      "train = bag.fit(xtrain,ytrain)\n",
      "pred = bag.prediction(xtest)\n",
      "\n",
      "acc= bag.accuracy(pred,ytest)\n",
      "print('Accuracy:',acc)\n",
      "\n",
      "print(ytrain.shape)\n",
      "    \n",
      "\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('Accuracy:', 91.97080291970804)\n",
        "(546,)\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import math\n",
      "class Boost():\n",
      "    \n",
      "    def __init__(self, b, n_ech):\n",
      "        self.b = b #nombre de clasiffieurs\n",
      "        self.n_ech = n_ech\n",
      "        #self.alphas = np.zeros((b,1))\n",
      "        \n",
      "    def fit(self, x, y):\n",
      "        #Poids des exemples normalis\u00e9s\n",
      "        self.w = np.zeros((len(x)))\n",
      "        for i in range(len(x)):\n",
      "            self.w[i] = 1/len(x) #distribution uniforme des poids initial\n",
      "        self.classifs = [tree.DecisionTreeClassifier(max_depth=1) for i in range(self.b)]\n",
      "        self.alphas = [[] for i in range(self.b)]\n",
      "\n",
      "        for i in range(self.b):\n",
      "            self.classifs[i].fit(x , y , sample_weight = self.w) #apprendre avec notre stump\n",
      "            pred = self.classifs[i].predict(x) #la sorti h(t)\n",
      "            idx_diff = np.where(pred != y)[0] #r\u00e9cup\u00e9r\u00e9 les indexe ou y != h(t)\n",
      "            \n",
      "            error = 0\n",
      "            for idx in idx_diff:\n",
      "                error += self.w[idx]\n",
      "                \n",
      "            #print('erreur = ',error) #si l'erreur es inf a 1/2 le classiffieur es s\u00e9l\u00e9ctionn\u00e9\n",
      "            if error < 0.5 : #si l'erreur es > a 0.5 ca nous int\u00e9resse pas\n",
      "                self.alphas[i] = float(0.5*np.log((1 - error) / error))\n",
      "                z = float(2*np.sqrt(error*(1-error)))\n",
      "                # Z facteur de normalisation\n",
      "                                    \n",
      "                for k in range(len(self.w)): #mettre a jour w\n",
      "                    self.w[k] *= (np.exp(-self.alphas[i] * y[k] * pred[k]) / (z*1.0))\n",
      "\n",
      "            else : self.alpha[i]= 0           \n",
      "        \n",
      "    def predict(self, x):\n",
      "        pred = []\n",
      "        for example in x:\n",
      "            results = np.array([self.classifs[i].predict(example.reshape(1 , x.shape[1])) for i in range(self.b)])\n",
      "            final = np.sign(np.dot(np.array(self.alphas).T , results))\n",
      "            pred.append(final)\n",
      "        return np.array(pred) \n",
      "    \n",
      "    def accuracy(self, pred , Y):\n",
      "        acc = pred - Y\n",
      "        return 100.0*len(np.where(acc == 0)[0])/len(pred)*1.0  \n",
      "\n",
      "            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "boost = Boost(50, len(xtrain)/10)\n",
      "boost.fit(xtrain , ytrain)\n",
      "pred = boost.predict(xtest)\n",
      "ytest = ytest.reshape(len(ytest),1)\n",
      "acc = boost.accuracy(pred, ytest)\n",
      "print acc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "96.3503649635\n"
       ]
      }
     ],
     "prompt_number": 46
    }
   ],
   "metadata": {}
  }
 ]
}